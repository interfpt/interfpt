{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Session 10 - NLTK | Real Time Voice Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speech to text conversion and real-time sentiment analysis\n",
    "In this project we are going to analyse the sentiment of the call. We are first going to convert the speech to text and the analyse the sentiment using TextBlob.\n",
    "\n",
    "TextBlob is a Python library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
    "\n",
    "`!pip install textblob` or `conda install --name tensorflow20 -c conda-forge textblob`\n",
    "\n",
    "NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\n",
    "\n",
    "`!pip install nltk` or `conda install --name tensorflow20 -c conda-forge nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing nltk does not install everthing in nltk. We will have to download somethings separately. We are going to download punkt, averaged_perceptron_tagger and brown.\n",
    "\n",
    "`\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gajendrasahu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/gajendrasahu/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/gajendrasahu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nltk.download()` opens a GUI by which you can view the packages which are already downloaded and even update or download new packages manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to import `TextBlob` and and create its object. We can see that tb is an object of TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Hi, please like this post!\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob as blob\n",
    "tb = blob('Hi, please like this post!')\n",
    "tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`help(tb)` will give you a list of all the functions which are available for tb. We will try some of them.\n",
    "\n",
    "`tags` returns a list of tuples of the form (word, POS tag). It is used to get the various parts of speech of the sentence.\n",
    "\n",
    " - NNP means proper noun, singular\n",
    " - NN means noun, singular\n",
    " - DT means determiner\n",
    " - IN means preposition/subordinating conjunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hi', 'NNP'),\n",
       " ('please', 'NN'),\n",
       " ('like', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('post', 'NN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`noun_phrases` returns a list of noun phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['hi'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sentiment` returns a tuple of form `(polarity, subjectivity )` where polarity is a float within the range [-1.0, 1.0] where -1.0 is very negative and 1.0 is very positive and subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.\n",
    "\n",
    "Let’s try another example. Here the polarity is 0.4583 which indicates a positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try another example. Here the `polarity is 0.4583` which indicates a `positive sentiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.4583333333333333, subjectivity=0.3666666666666667)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb = blob('I love this channel. There are many useful posts here!')\n",
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Time Voice Recording\n",
    "To install the necessary packages you can run the following commands in anaconda in the administrator mode:-\n",
    "\n",
    "`pip install SpeechRecognition` or `conda install --name tensorflow20 -c conda-forge SpeechRecognition`\n",
    "\n",
    "`conda install pyaudio` or `conda install --name tensorflow20 -c conda-forge pyaudio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing `speech_recognition` we are going to convert audio from our microphone into text. For this we are going to use `recognize_google()`. As `timeout=2` it will stop listening if there is no audio for 2 seconds. We are displaying the text and its sentiment at the end. For the example below we have got a negative `polarity` which indicates that the sentiment is `negative`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say Something...\n",
      "I hate this\n",
      "Sentiment(polarity=-0.8, subjectivity=0.9)\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print('Say Something...')\n",
    "    audio = r.listen(source, timeout=2)\n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "        tb = blob(text)\n",
    "        print(text)\n",
    "        print(tb.sentiment)\n",
    "    except:\n",
    "        print('Sorry... Try again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to run the same piece of code 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num = 10\n",
    "index = 0\n",
    "while(index<iter_num):\n",
    "    with sr.Microphone() as source:\n",
    "        print()\n",
    "        print('Say Something...')\n",
    "        audio = r.listen(source, timeout=3)\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            tb = blob(text)\n",
    "            print(text)\n",
    "            print(tb.sentiment)\n",
    "        except:\n",
    "            print('Sorry... Try again')\n",
    "        index = index + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
